[34mAuto commit by fitlog[0m
Running with args:Namespace(batch_size=128, cuda=True, data_dir='../../data', data_src='all_data', dropout=0.3, embed_size=128, epochs=4, gpu='1', hidden_size=128, learning_rate=0.001, log_path='./run_records.log', max_seq_len=500, min_count=10, model='CNNText', model_dir='../../data/models', model_suffix='essay_at_least_1_teacher_referred_donor', num_layers=2, optim='Adam', patience=2, predict=False, prepare=True, prepare_dir='../../data/prepare/', pretrain=False, pretrain_model='None', reload_model_name='best_LSTMText_accuracy_2019-06-14-04-01-48', result_dir='../../data/results/', show_data=False, target_var='at_least_1_teacher_referred_donor', text_var='essay', train=True, vocab_data='vocab_essay_at_least_1_teacher_referred_donor.data', vocab_dir='../../data/vocab', weight_decay=0.0)
Checking the data files...
Checking the data files...
Generateing essay - at_least_1_teacher_referred_donor
Loading data from ../../data/essays_all_outcome.csv ...
nums:(291519,131329,44772)
Over Sample mode
subset nums:(291519,131329,44772)
0
tokenize train set
Tokenizing data , total num:291519
Tokenized:291519/291519
ATTENTION TYPE:<class 'float'> * 1038
tokenize val set
Tokenizing data , total num:131329
Tokenized:131329/131329
ATTENTION TYPE:<class 'float'> * 811
tokenize test set
Tokenizing data , total num:44772
Tokenized:44772/44772
ATTENTION TYPE:<class 'float'> * 688
Building Fastnlp dataset.
Over Sampling...
Building Fastnlp vocabulary.
Building id-presentation for train_set and test_set.
1070
Building target-vector for train_set and test_set.
Data Sizes (425318, 175340, 44772)
Saving vocab(TextData)...
Done with preparing!
(vocab_size,class_num,seq_len):(32305,2,1070)
No pretrained model with be used.
vocabsize:32305
Using CNN Model.
CNNText(
  (embed): Embedding(
    32305, 128
    (dropout): Dropout(p=0.0)
  )
  (conv_pool): ConvMaxpool(
    (convs): ModuleList(
      (0): Conv1d(128, 3, kernel_size=(3,), stride=(1,), padding=(2,))
      (1): Conv1d(128, 4, kernel_size=(4,), stride=(1,), padding=(2,))
      (2): Conv1d(128, 5, kernel_size=(5,), stride=(1,), padding=(2,))
    )
  )
  (dropout): Dropout(p=0.3)
  (fc): Linear(in_features=12, out_features=2, bias=True)
)
train_size:425318 ; val_size:175340 ; test_size:44772
Using Adam as optimizer.
input fields after batch(if batch size is 2):
	words: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2, 1070]) 
	seq_len: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) 
target fields after batch(if batch size is 2):
	target: (1)type:torch.Tensor (2)dtype:torch.int64, (3)shape:torch.Size([2]) 

training epochs started 2019-06-15-12-04-33
loss:2.36143
loss:1.69545
loss:1.27896
loss:1.06571
loss:1.06119
loss:1.01771
loss:1.07156
loss:0.99735
loss:1.03409
loss:0.94887
loss:0.93389
loss:0.99657
loss:0.93662
loss:0.91741
loss:0.88483
loss:0.91750
loss:0.81514
loss:0.89272
loss:0.84935
loss:0.83725
loss:0.85206
loss:0.81862
loss:0.79903
loss:0.80278
loss:0.79290
loss:0.82147
loss:0.84501
loss:0.80219
loss:0.80873
loss:0.79212
loss:0.77114
loss:0.79187
loss:0.77816
loss:0.78175
loss:0.75938
loss:0.75955
loss:0.79904
loss:0.77125
loss:0.77017
loss:0.75856
loss:0.75797
loss:0.74985
loss:0.72301
loss:0.76785
loss:0.73974
loss:0.75875
loss:0.71060
loss:0.74025
loss:0.74511
loss:0.74235
loss:0.73324
loss:0.74231
loss:0.74188
loss:0.71122
loss:0.74994
loss:0.71762
loss:0.72320
loss:0.71783
loss:0.72407
loss:0.72143
loss:0.72006
loss:0.71035
loss:0.71188
loss:0.70200
loss:0.70689
loss:0.70896
loss:0.70842
loss:0.70470
loss:0.71845
loss:0.71906
loss:0.70119
loss:0.71786
loss:0.71136
loss:0.68596
loss:0.70542
loss:0.70916
loss:0.70328
loss:0.70185
loss:0.70602
loss:0.71221
loss:0.70010
loss:0.72148
loss:0.71554
loss:0.70458
loss:0.71887
loss:0.70908
loss:0.70404
loss:0.69829
loss:0.69609
loss:0.70173
loss:0.69270
loss:0.70614
loss:0.70143
loss:0.69726
loss:0.70102
loss:0.70824
loss:0.70756
loss:0.70390
loss:0.70026
loss:0.69790
loss:0.69664
loss:0.70782
loss:0.69899
loss:0.68950
loss:0.69260
loss:0.70473
loss:0.70544
loss:0.69717
loss:0.70089
loss:0.69367
loss:0.69832
loss:0.69741
loss:0.69996
loss:0.69515
loss:0.70059
loss:0.69338
loss:0.69168
loss:0.69626
loss:0.70043
loss:0.69667
loss:0.69464
loss:0.69684
loss:0.69040
loss:0.70651
loss:0.69668
loss:0.70227
loss:0.69167
loss:0.69101
loss:0.69573
loss:0.69693
loss:0.69446
loss:0.69392
loss:0.70692
loss:0.68676
loss:0.69944
loss:0.69689
loss:0.69318
loss:0.69554
loss:0.70136
loss:0.70235
loss:0.69435
loss:0.69673
loss:0.69439
loss:0.69771
loss:0.69454
loss:0.68944
loss:0.69535
loss:0.68890
loss:0.69490
loss:0.70435
loss:0.69190
loss:0.68917
loss:0.70057
loss:0.68957
loss:0.69829
loss:0.69442
loss:0.69472
loss:0.69488
loss:0.69685
loss:0.69421
loss:0.69448
loss:0.69390
loss:0.69485
loss:0.69845
loss:0.68895
loss:0.70288
loss:0.69420
loss:0.69848
loss:0.69723
loss:0.69511
loss:0.69024
loss:0.69212
loss:0.69026
loss:0.69798
loss:0.69140
loss:0.68863
loss:0.68675
loss:0.68828
loss:0.69373
loss:0.68761
loss:0.68498
loss:0.69512
loss:0.70002
loss:0.68996
loss:0.69553
loss:0.68618
loss:0.69067
loss:0.68990
loss:0.69223
loss:0.68578
loss:0.70099
loss:0.68909
loss:0.68665
loss:0.69530
loss:0.69216
loss:0.68953
loss:0.69125
loss:0.69145
loss:0.69435
loss:0.69614
loss:0.69848
loss:0.68832
loss:0.69093
loss:0.68489
loss:0.69389
loss:0.69730
loss:0.69007
loss:0.69243
loss:0.69145
loss:0.69483
loss:0.69064
loss:0.69339
loss:0.69160
loss:0.68352
loss:0.69702
loss:0.70042
loss:0.69022
loss:0.68873
loss:0.69627
loss:0.69217
loss:0.68950
loss:0.69591
loss:0.69218
loss:0.69336
loss:0.69333
loss:0.68424
loss:0.68785
loss:0.68943
loss:0.68621
loss:0.69236
loss:0.68786
loss:0.69081
loss:0.69605
loss:0.68642
loss:0.69739
loss:0.69287
loss:0.69436
loss:0.68747
loss:0.69680
loss:0.69585
loss:0.68708
loss:0.68980
loss:0.69313
loss:0.69229
loss:0.69249
loss:0.69209
loss:0.69420
loss:0.69163
loss:0.69107
loss:0.68607
loss:0.69015
loss:0.70141
loss:0.68986
loss:0.70012
loss:0.69352
loss:0.68606
loss:0.68812
loss:0.69578
loss:0.69689
loss:0.68950
loss:0.69282
loss:0.69386
loss:0.69188
loss:0.68690
loss:0.69595
loss:0.69453
loss:0.69287
loss:0.68809
loss:0.68875
loss:0.68895
loss:0.69906
loss:0.68587
loss:0.69114
loss:0.68842
loss:0.69206
loss:0.68828
loss:0.68937
loss:0.69597
loss:0.69179
loss:0.69030
loss:0.69380
loss:0.69773
loss:0.69265
loss:0.69040
loss:0.69523
loss:0.69512
loss:0.69277
loss:0.69161
loss:0.69366
loss:0.68975
loss:0.68685
loss:0.69084
loss:0.69423
loss:0.69266
loss:0.68609
loss:0.68689
loss:0.69335
loss:0.69536
loss:0.68494
loss:0.68643
loss:0.69974
loss:0.68719
loss:0.69421
loss:0.68959
loss:0.69319
loss:0.68897
loss:0.69108
loss:0.68622
loss:0.68685
loss:0.69121
loss:0.68625
loss:0.69163
loss:0.69544
loss:0.69486
loss:0.69155
loss:0.69258
loss:0.68808
loss:0.68740
loss:0.68910
loss:0.68687
loss:0.68810
loss:0.69103
loss:0.68771
loss:0.68764
loss:0.68735
loss:0.69749
loss:0.69371
loss:0.69405
loss:0.68741
loss:0.68683
loss:0.69183
loss:0.69011
loss:0.68994
loss:0.69032
loss:0.69024
loss:0.69215
loss:0.69406
loss:0.69065
loss:0.69371
loss:0.69169
loss:0.69105
loss:0.69681
loss:0.69564
loss:0.69848
loss:0.68876
loss:0.68574
loss:0.69568
loss:0.68800
loss:0.69063
loss:0.68777
loss:0.68987
loss:0.68367
loss:0.69106
loss:0.68992
loss:0.68884
loss:0.69411
loss:0.68967
loss:0.68874
loss:0.68959
loss:0.68926
loss:0.69299
loss:0.68765
loss:0.69629
loss:0.68840
loss:0.68292
loss:0.69413
loss:0.69663
loss:0.68575
loss:0.69125
loss:0.68565
loss:0.69177
loss:0.68702
loss:0.68675
loss:0.68898
loss:0.69505
loss:0.68984
loss:0.68973
loss:0.69858
loss:0.69056
loss:0.69081
loss:0.68761
loss:0.68563
loss:0.69400
loss:0.68501
loss:0.68971
loss:0.69604
loss:0.68747
loss:0.69352
loss:0.69006
loss:0.68969
loss:0.69440
loss:0.68875
loss:0.69134
loss:0.69313
loss:0.69542
loss:0.68728
loss:0.69095
loss:0.69220
loss:0.69162
loss:0.69026
loss:0.69217
loss:0.68865
loss:0.68949
loss:0.68936
loss:0.69130
loss:0.68754
loss:0.68790
loss:0.69191
loss:0.68860
loss:0.68886
loss:0.68836
loss:0.69309
loss:0.68546
loss:0.69200
loss:0.68424
loss:0.68872
loss:0.69315
loss:0.68742
loss:0.68575
loss:0.68268
loss:0.69180
loss:0.69307
loss:0.69540
loss:0.69230
loss:0.69168
loss:0.68765
loss:0.69192
loss:0.68537
loss:0.68622
loss:0.69855
loss:0.68341
loss:0.68583
loss:0.68977
loss:0.69263
loss:0.68473
loss:0.69170
loss:0.69208
loss:0.69032
loss:0.68934
loss:0.68794
loss:0.68564
loss:0.68486
loss:0.68600
loss:0.68663
loss:0.68137
loss:0.68895
loss:0.68928
loss:0.69361
loss:0.69561
loss:0.68423
loss:0.68972
loss:0.68317
loss:0.69268
loss:0.68226
loss:0.69085
loss:0.68792
loss:0.69271
loss:0.68947
loss:0.68515
loss:0.68402
loss:0.68793
loss:0.69003
loss:0.69203
loss:0.68769
loss:0.69073
loss:0.69361
loss:0.69133
loss:0.68575
loss:0.69425
loss:0.69438
loss:0.69048
loss:0.68156
loss:0.68230
loss:0.68361
loss:0.68780
loss:0.68987
loss:0.68681
loss:0.69091
loss:0.68933
loss:0.68995
loss:0.68239
loss:0.68105
loss:0.68372
loss:0.69102
loss:0.68555
loss:0.68870
loss:0.68201
loss:0.68955
loss:0.68363
loss:0.68273
loss:0.69132
loss:0.68417
loss:0.68857
loss:0.68987
loss:0.68428
loss:0.69369
loss:0.68638
loss:0.68254
loss:0.68386
loss:0.68860
loss:0.68012
loss:0.69304
loss:0.68828
loss:0.68145
loss:0.69127
loss:0.69315
loss:0.68641
loss:0.68382
loss:0.69016
loss:0.69009
loss:0.68901
loss:0.68739
loss:0.68886
loss:0.69120
loss:0.68499
loss:0.68431
loss:0.69140
loss:0.68723
loss:0.68735
loss:0.68420
loss:0.68185
loss:0.68321
loss:0.69391
loss:0.69649
loss:0.68729
loss:0.68630
loss:0.69763
loss:0.69028
loss:0.68957
loss:0.69446
loss:0.69327
loss:0.69320
loss:0.69724
loss:0.69043
loss:0.68570
loss:0.68845
loss:0.68554
loss:0.68337
loss:0.68060
loss:0.68539
loss:0.68398
loss:0.68727
loss:0.69057
loss:0.69389
loss:0.68827
loss:0.69416
loss:0.68939
loss:0.68627
loss:0.68125
loss:0.69049
loss:0.69020
loss:0.68851
loss:0.68507
loss:0.68238
loss:0.68823
loss:0.68074
loss:0.68609
loss:0.69050
loss:0.69139
loss:0.69070
loss:0.68815
loss:0.69687
loss:0.69016
loss:0.68271
loss:0.69272
loss:0.68796
loss:0.68881
loss:0.68456
loss:0.67900
loss:0.68594
loss:0.69119
loss:0.69080
loss:0.69178
loss:0.68955
loss:0.68341
loss:0.68183
loss:0.68419
loss:0.68334
loss:0.68885
loss:0.68763
loss:0.68575
loss:0.68731
loss:0.68421
loss:0.68548
loss:0.68746
loss:0.69263
loss:0.68965
loss:0.69031
loss:0.69092
loss:0.67636
loss:0.68738
loss:0.68965
loss:0.68588
loss:0.69839
loss:0.68617
loss:0.68245
loss:0.68767
loss:0.68037
loss:0.69465
loss:0.68473
loss:0.68069
loss:0.68285
loss:0.68852
loss:0.68735
loss:0.68330
loss:0.68447
loss:0.68803
loss:0.68651
loss:0.68299
loss:0.68444
loss:0.69043
loss:0.68323
loss:0.68485
loss:0.69281
loss:0.68180
loss:0.69137
loss:0.69095
loss:0.68975
loss:0.68048
loss:0.68841
loss:0.68540
loss:0.68264
loss:0.69129
loss:0.68661
loss:0.68368
loss:0.68408
loss:0.68982
loss:0.68139
loss:0.68114
loss:0.69313
loss:0.68024
loss:0.68068
loss:0.68844
loss:0.68273
loss:0.67738
loss:0.68340
loss:0.68387
loss:0.68197
loss:0.68355
loss:0.67344
loss:0.69197
loss:0.69575
loss:0.68968
loss:0.68663
loss:0.68849
loss:0.67740
loss:0.68648
loss:0.67835
loss:0.68967
loss:0.68187
loss:0.68099
loss:0.68226
loss:0.68252
loss:0.68831
loss:0.68287
loss:0.68937
loss:0.68978
loss:0.68095
loss:0.68581
loss:0.68923
loss:0.67956
loss:0.67659
loss:0.68568
loss:0.68904
Evaluation at Epoch 1/4. Step:3323/13292. AccuracyMetric: acc=0.54785

loss:0.68732
loss:0.68816
loss:0.68463
loss:0.67772
loss:0.66980
loss:0.68889
loss:0.69510
loss:0.68465
loss:0.68006
loss:0.68137
loss:0.67872
loss:0.68191
loss:0.67837
loss:0.67772
loss:0.68354
loss:0.68403
loss:0.68214
loss:0.68256
loss:0.67671
loss:0.68640
loss:0.68742
loss:0.67424
loss:0.68176
loss:0.68619
loss:0.68320
loss:0.68085
loss:0.68174
loss:0.68257
loss:0.66822
loss:0.68364
loss:0.68249
loss:0.69320
loss:0.68445
loss:0.67365
loss:0.68187
loss:0.67585
loss:0.67910
loss:0.68242
loss:0.67959
loss:0.68027
loss:0.68807
loss:0.68607
loss:0.67851
loss:0.68372
loss:0.68131
loss:0.68239
loss:0.68388
loss:0.68755
loss:0.67294
loss:0.68363
loss:0.68162
loss:0.67951
loss:0.69041
loss:0.68329
loss:0.68938
loss:0.67459
loss:0.67805
loss:0.69032
loss:0.67562
loss:0.69511
loss:0.68751
loss:0.68937
loss:0.68479
loss:0.67558
loss:0.68407
loss:0.67887
loss:0.68403
loss:0.68994
loss:0.68866
loss:0.69400
loss:0.68301
loss:0.68780
loss:0.68519
loss:0.67942
loss:0.68226
loss:0.68720
loss:0.67409
loss:0.67996
loss:0.68855
loss:0.68964
loss:0.68161
loss:0.68031
loss:0.66874
loss:0.68506
loss:0.67759
loss:0.69170
loss:0.67504
loss:0.68325
loss:0.67630
loss:0.68671
loss:0.67788
loss:0.66804
loss:0.68779
loss:0.67455
loss:0.67839
loss:0.66442
loss:0.67659
loss:0.68435
loss:0.67667
loss:0.69083
loss:0.68521
loss:0.67607
loss:0.68489
loss:0.68922
loss:0.68210
loss:0.68688
loss:0.68181
loss:0.67121
loss:0.67707
loss:0.68243
loss:0.67559
loss:0.67644
loss:0.67980
loss:0.68838
loss:0.68622
loss:0.68767
loss:0.67885
loss:0.68426
loss:0.69203
loss:0.67190
loss:0.69586
loss:0.69487
loss:0.67912
loss:0.69025
loss:0.67795
loss:0.68352
loss:0.67936
loss:0.67172
loss:0.68094
loss:0.68421
loss:0.68604
loss:0.68344
loss:0.67702
loss:0.67930
loss:0.68854
loss:0.68763
loss:0.68235
loss:0.67910
loss:0.67248
loss:0.66876
loss:0.69266
loss:0.69097
loss:0.67312
loss:0.67432
loss:0.67737
loss:0.68569
loss:0.67867
loss:0.68183
loss:0.68180
loss:0.68175
loss:0.67633
loss:0.68063
loss:0.67825
loss:0.67959
loss:0.67989
loss:0.68836
loss:0.68145
loss:0.68063
loss:0.68178
loss:0.68161
loss:0.67965
loss:0.67748
loss:0.67478
loss:0.68179
loss:0.68699
loss:0.67425
loss:0.68117
loss:0.68816
loss:0.68058
loss:0.67465
loss:0.69007
loss:0.67824
loss:0.67461
loss:0.68277
loss:0.68208
loss:0.68096
loss:0.68779
loss:0.68666
loss:0.67447
loss:0.67836
loss:0.68288
loss:0.66341
loss:0.67259
loss:0.67992
loss:0.68279
loss:0.67760
loss:0.67919
loss:0.68056
loss:0.68000
loss:0.68225
loss:0.67440
loss:0.67040
loss:0.68118
loss:0.67698
loss:0.69193
loss:0.69073
loss:0.67623
loss:0.68641
loss:0.68498
loss:0.67957
loss:0.67500
loss:0.66718
loss:0.68149
loss:0.67561
loss:0.68286
loss:0.68146
loss:0.67706
loss:0.67797
loss:0.67327
loss:0.68931
loss:0.66489
loss:0.67014
loss:0.67005
loss:0.68359
loss:0.68255
loss:0.68468
loss:0.67745
loss:0.68815
loss:0.66286
loss:0.67030
loss:0.67514
loss:0.69507
loss:0.67995
loss:0.67410
loss:0.68154
loss:0.67404
loss:0.67670
loss:0.68486
loss:0.69339
loss:0.67203
loss:0.67152
loss:0.68171
loss:0.67588
loss:0.67292
loss:0.67952
loss:0.66994
loss:0.66399
loss:0.67590
loss:0.68037
loss:0.68266
loss:0.68222
loss:0.66655
loss:0.67362
loss:0.69305
loss:0.68873
loss:0.68339
loss:0.67540
loss:0.68358
loss:0.68114
loss:0.68654
loss:0.68373
loss:0.68069
loss:0.67206
loss:0.67095
loss:0.68456
loss:0.68370
loss:0.67903
loss:0.69107
loss:0.67609
loss:0.67875
loss:0.67702
loss:0.67887
loss:0.69013
loss:0.68005
loss:0.68463
loss:0.67516
loss:0.67784
loss:0.68886
loss:0.68465
loss:0.66793
loss:0.67556
loss:0.67401
loss:0.68657
loss:0.68879
loss:0.67938
loss:0.67270
loss:0.67122
loss:0.67641
loss:0.67182
loss:0.68297
loss:0.68597
loss:0.67900
loss:0.67480
loss:0.67531
loss:0.67098
loss:0.67849
loss:0.65596
loss:0.66148
loss:0.67144
loss:0.67508
loss:0.67957
loss:0.66150
loss:0.68039
loss:0.68421
loss:0.68305
loss:0.66670
loss:0.68364
loss:0.68448
loss:0.67752
loss:0.67174
loss:0.67450
loss:0.67234
loss:0.69035
loss:0.67943
loss:0.68906
loss:0.68477
loss:0.68434
loss:0.66268
loss:0.68509
loss:0.69194
loss:0.67274
loss:0.68328
loss:0.66024
loss:0.69018
loss:0.67895
loss:0.67707
loss:0.68550
loss:0.67823
loss:0.68124
loss:0.67180
loss:0.69004
loss:0.68108
loss:0.68128
loss:0.67972
loss:0.68105
loss:0.67922
loss:0.68162
loss:0.66392
loss:0.67661
loss:0.68222
loss:0.67637
loss:0.67445
loss:0.67379
loss:0.68273
loss:0.68395
loss:0.67247
loss:0.67484
loss:0.67215
loss:0.67023
loss:0.67785
loss:0.67320
loss:0.68439
loss:0.67914
loss:0.68175
loss:0.67764
loss:0.67285
loss:0.67769
loss:0.67419
loss:0.68034
loss:0.67947
loss:0.67313
loss:0.67016
loss:0.67814
loss:0.67546
loss:0.67712
loss:0.67034
loss:0.66262
loss:0.68984
loss:0.67793
loss:0.68254
loss:0.68138
loss:0.67013
loss:0.67315
loss:0.66753
loss:0.67453
loss:0.67100
loss:0.67272
loss:0.67912
loss:0.68223
loss:0.67891
loss:0.67567
loss:0.67363
loss:0.65713
loss:0.67840
loss:0.67043
loss:0.66216
loss:0.68523
loss:0.67535
loss:0.67872
loss:0.67503
loss:0.67339
loss:0.68379
loss:0.68016
loss:0.66270
loss:0.67623
loss:0.68551
loss:0.67037
loss:0.68486
loss:0.68327
loss:0.67594
loss:0.67976
loss:0.68702
loss:0.66428
loss:0.67846
loss:0.67106
loss:0.67295
loss:0.67376
loss:0.68094
loss:0.69185
loss:0.66788
loss:0.66089
loss:0.67275
loss:0.67419
loss:0.68232
loss:0.68013
loss:0.66278
loss:0.67384
loss:0.69232
loss:0.65867
loss:0.68285
loss:0.67649
loss:0.69066
loss:0.68566
loss:0.66964
loss:0.67464
loss:0.67587
loss:0.68117
loss:0.66925
loss:0.67689
loss:0.67295
loss:0.68726
loss:0.67138
loss:0.67093
loss:0.68151
loss:0.68612
loss:0.67663
loss:0.67311
loss:0.68115
loss:0.67644
loss:0.67360
loss:0.67329
loss:0.67994
loss:0.67928
loss:0.66471
loss:0.67293
loss:0.67151
loss:0.67259
loss:0.68178
loss:0.66357
loss:0.66819
loss:0.67254
loss:0.67960
loss:0.68236
loss:0.67384
loss:0.66562
loss:0.67170
loss:0.67396
loss:0.68910
loss:0.69579
loss:0.67578
loss:0.66514
loss:0.67179
loss:0.67474
loss:0.67949
loss:0.67303
loss:0.67331
loss:0.68436
loss:0.67664
loss:0.68717
loss:0.67095
loss:0.67420
loss:0.67874
loss:0.66883
loss:0.69151
loss:0.68071
loss:0.67521
loss:0.67140
loss:0.68608
loss:0.67532
loss:0.67101
loss:0.67862
loss:0.68007
loss:0.66830
loss:0.68343
loss:0.67113
loss:0.67490
loss:0.68589
loss:0.67478
loss:0.66626
loss:0.67578
loss:0.67676
loss:0.67860
loss:0.68559
loss:0.66392
loss:0.68653
loss:0.67833
loss:0.67767
loss:0.67835
loss:0.65843
loss:0.67524
loss:0.67788
loss:0.67805
loss:0.67498
loss:0.68164
loss:0.67317
loss:0.66573
loss:0.66856
loss:0.67897
loss:0.67661
loss:0.67433
loss:0.67990
loss:0.66338
loss:0.67955
loss:0.66722
loss:0.68075
loss:0.67620
loss:0.66389
loss:0.68226
loss:0.67180
loss:0.67306
loss:0.68287
loss:0.67113
loss:0.67052
loss:0.66790
loss:0.66013
loss:0.67747
loss:0.67237
loss:0.67319
loss:0.65923
loss:0.67915
loss:0.67122
loss:0.67817
loss:0.66425
loss:0.68781
loss:0.66516
loss:0.67292
loss:0.68620
loss:0.67141
loss:0.67777
loss:0.67183
loss:0.65560
loss:0.66863
loss:0.67429
loss:0.66868
loss:0.69230
loss:0.68534
loss:0.67403
loss:0.67454
loss:0.67864
loss:0.67747
loss:0.68114
loss:0.67377
loss:0.67305
loss:0.66604
loss:0.67368
loss:0.66843
loss:0.67228
loss:0.66850
loss:0.67002
loss:0.67609
loss:0.68700
loss:0.68892
loss:0.67012
loss:0.68690
loss:0.67137
loss:0.66121
loss:0.66647
loss:0.67392
loss:0.66190
loss:0.67496
loss:0.66215
loss:0.66999
loss:0.68425
loss:0.67333
loss:0.67095
loss:0.66512
loss:0.67056
loss:0.63926
loss:0.68926
loss:0.68281
loss:0.67037
loss:0.68503
loss:0.67772
loss:0.67659
loss:0.66443
loss:0.66574
loss:0.67826
loss:0.67343
loss:0.65170
loss:0.67668
loss:0.67217
loss:0.67037
loss:0.66764
loss:0.68206
loss:0.67038
loss:0.67151
loss:0.67367
loss:0.68064
loss:0.67167
loss:0.66857
loss:0.66802
loss:0.67180
loss:0.67558
loss:0.67047
loss:0.68629
loss:0.67815
loss:0.67208
loss:0.67559
loss:0.67153
loss:0.66139
loss:0.67379
loss:0.67969
loss:0.67332
loss:0.67602
loss:0.67016
loss:0.67507
loss:0.67618
loss:0.67636
loss:0.66485
loss:0.67173
loss:0.68701
loss:0.67669
loss:0.66994
loss:0.67627
loss:0.67642
loss:0.65955
loss:0.67990
loss:0.67085
loss:0.67921
loss:0.67624
loss:0.67222
loss:0.66270
loss:0.66085
loss:0.66017
loss:0.67497
loss:0.67696
loss:0.68395
loss:0.67187
loss:0.67757
loss:0.67666
loss:0.67286
loss:0.67069
loss:0.66385
loss:0.68228
loss:0.66742
loss:0.66859
loss:0.68056
loss:0.67181
loss:0.67197
loss:0.66660
loss:0.68229
loss:0.66815
loss:0.66845
loss:0.66169
loss:0.67033
loss:0.66768
loss:0.67064
loss:0.67018
loss:0.67842
loss:0.67349
loss:0.67553
loss:0.67460
loss:0.67899
loss:0.67156
loss:0.69036
loss:0.69630
loss:0.66673
loss:0.67384
loss:0.67870
loss:0.66976
loss:0.66459
loss:0.66530
loss:0.65987
loss:0.67759
loss:0.66637
Evaluation at Epoch 2/4. Step:6646/13292. AccuracyMetric: acc=0.552749

loss:0.66891
loss:0.65143
loss:0.65238
loss:0.65707
loss:0.64786
loss:0.66631
loss:0.65917
loss:0.65041
loss:0.65925
loss:0.65544
loss:0.65673
loss:0.65712
loss:0.64671
loss:0.66894
loss:0.65509
loss:0.65094
loss:0.65168
loss:0.68774
loss:0.64244
loss:0.66426
loss:0.65095
loss:0.64931
loss:0.64894
loss:0.65841
loss:0.65823
loss:0.64549
loss:0.67296
loss:0.63951
loss:0.66918
loss:0.67060
loss:0.65825
loss:0.68236
loss:0.66363
loss:0.66872
loss:0.66666
loss:0.64911
loss:0.67399
loss:0.64634
loss:0.67612
loss:0.67284
loss:0.66578
loss:0.67016
loss:0.66067
loss:0.66695
loss:0.68731
loss:0.66410
loss:0.66959
loss:0.65372
loss:0.65592
loss:0.67163
loss:0.66782
loss:0.66749
loss:0.66680
loss:0.65636
loss:0.66217
loss:0.66146
loss:0.67937
loss:0.65728
loss:0.65195
loss:0.66202
loss:0.67041
loss:0.66181
loss:0.66229
loss:0.64591
loss:0.66663
loss:0.67744
loss:0.65912
loss:0.65456
loss:0.66981
loss:0.64864
loss:0.65683
loss:0.66090
loss:0.64905
loss:0.67042
loss:0.64491
loss:0.66084
loss:0.66625
loss:0.66580
loss:0.65233
loss:0.65765
loss:0.66176
loss:0.67169
loss:0.65271
loss:0.66602
loss:0.66029
loss:0.66810
loss:0.67007
loss:0.65266
loss:0.66572
loss:0.65806
loss:0.66269
loss:0.66572
loss:0.67110
loss:0.67194
loss:0.65255
loss:0.65624
loss:0.66006
loss:0.65986
loss:0.67537
loss:0.66992
loss:0.69005
loss:0.66027
loss:0.65867
loss:0.67916
loss:0.66283
loss:0.67611
loss:0.66751
loss:0.66187
loss:0.65891
loss:0.66251
loss:0.66083
loss:0.67420
loss:0.65139
loss:0.66479
loss:0.64501
loss:0.66347
loss:0.67126
loss:0.68529
loss:0.66159
loss:0.65204
loss:0.64695
loss:0.65620
loss:0.67701
loss:0.66141
loss:0.67155
loss:0.67072
loss:0.67031
loss:0.65189
loss:0.65988
loss:0.64848
loss:0.66663
loss:0.66113
loss:0.66737
loss:0.65361
loss:0.67577
loss:0.68291
loss:0.65360
loss:0.67613
loss:0.66167
loss:0.67157
loss:0.65869
loss:0.66484
loss:0.66155
loss:0.64299
loss:0.67626
loss:0.67954
loss:0.66786
loss:0.65697
loss:0.65460
loss:0.64453
loss:0.66172
loss:0.65862
loss:0.67066
loss:0.67526
loss:0.65763
loss:0.66685
loss:0.66026
loss:0.66450
loss:0.66229
loss:0.65395
loss:0.65042
loss:0.65776
loss:0.64070
loss:0.66259
loss:0.65121
loss:0.66372
loss:0.65820
loss:0.66890
loss:0.66893
loss:0.65196
loss:0.65640
loss:0.65861
loss:0.66265
loss:0.63956
loss:0.66616
loss:0.66670
loss:0.64143
loss:0.66361
loss:0.64989
loss:0.65452
loss:0.66335
loss:0.68243
loss:0.65121
loss:0.67722
loss:0.66815
loss:0.65869
loss:0.66588
loss:0.66185
loss:0.65353
loss:0.65961
loss:0.64656
loss:0.67144
loss:0.67521
loss:0.67379
loss:0.66484
loss:0.64102
loss:0.65558
loss:0.66565
loss:0.65949
loss:0.66299
loss:0.65726
loss:0.63764
loss:0.66872
loss:0.66414
loss:0.66804
loss:0.67497
loss:0.66783
loss:0.67221
loss:0.67292
loss:0.65579
loss:0.66971
loss:0.64414
loss:0.64086
loss:0.65958
loss:0.68554
loss:0.64783
loss:0.66622
loss:0.65597
loss:0.64571
loss:0.63927
loss:0.64623
loss:0.65276
loss:0.66457
loss:0.65700
loss:0.66991
loss:0.63645
loss:0.66445
loss:0.65311
loss:0.67249
loss:0.66263
loss:0.65964
loss:0.66940
loss:0.64630
loss:0.66450
loss:0.65280
loss:0.67216
loss:0.65791
loss:0.66296
loss:0.65641
loss:0.67284
loss:0.65346
loss:0.65659
loss:0.64850
loss:0.66820
loss:0.65538
loss:0.67890
loss:0.65891
loss:0.66114
loss:0.66720
loss:0.66924
loss:0.67031
loss:0.67419
loss:0.66867
loss:0.66697
loss:0.66523
loss:0.65402
loss:0.65350
loss:0.66354
loss:0.65338
loss:0.66284
loss:0.66655
loss:0.67220
loss:0.65164
loss:0.68622
loss:0.65275
loss:0.65669
loss:0.66327
loss:0.66607
loss:0.66552
loss:0.65942
loss:0.67496
loss:0.65563
loss:0.66414
loss:0.64069
loss:0.66800
loss:0.67636
loss:0.66789
loss:0.66012
loss:0.67324
loss:0.64345
loss:0.64637
loss:0.64362
loss:0.64683
loss:0.66941
loss:0.67377
loss:0.65517
loss:0.67987
loss:0.65953
loss:0.65776
loss:0.65616
loss:0.65564
loss:0.66651
loss:0.65588
loss:0.67249
loss:0.64566
loss:0.67217
loss:0.67332
loss:0.66662
loss:0.65576
loss:0.66126
loss:0.65132
loss:0.65621
loss:0.65249
loss:0.65514
loss:0.65492
loss:0.67153
loss:0.66214
loss:0.67637
loss:0.66860
loss:0.66518
loss:0.67001
loss:0.66609
loss:0.66115
loss:0.65670
loss:0.66432
loss:0.64723
loss:0.65205
loss:0.67240
loss:0.64905
loss:0.65669
loss:0.65751
loss:0.65335
loss:0.66363
loss:0.65566
loss:0.64728
loss:0.65231
loss:0.66241
loss:0.67101
loss:0.66235
loss:0.64894
loss:0.66354
loss:0.65901
loss:0.66147
loss:0.64425
loss:0.65242
loss:0.65049
loss:0.64990
loss:0.65611
loss:0.65341
loss:0.65300
loss:0.65412
loss:0.65777
loss:0.66682
loss:0.65745
loss:0.65205
loss:0.66348
loss:0.65823
loss:0.66733
loss:0.66472
loss:0.64393
loss:0.66494
loss:0.64724
loss:0.66056
loss:0.64664
loss:0.66176
loss:0.67209
loss:0.66437
loss:0.68095
loss:0.68036
loss:0.66860
loss:0.66358
loss:0.66177
loss:0.66262
loss:0.65684
loss:0.64674
loss:0.64350
loss:0.64473
loss:0.66184
loss:0.64929
loss:0.64255
loss:0.66056
loss:0.64444
loss:0.64754
loss:0.68108
loss:0.65925
loss:0.66181
loss:0.66313
loss:0.64715
loss:0.68278
loss:0.67079
loss:0.64497
loss:0.65843
loss:0.64085
loss:0.64848
loss:0.65656
loss:0.64624
loss:0.66915
loss:0.67683
loss:0.65290
loss:0.64519
loss:0.65411
loss:0.64349
loss:0.64627
loss:0.66359
loss:0.64527
loss:0.67068
loss:0.65322
loss:0.67591
loss:0.64764
loss:0.64196
loss:0.65473
loss:0.66955
loss:0.63373
loss:0.66779
loss:0.68013
loss:0.65201
loss:0.64194
loss:0.65528
loss:0.64717
loss:0.64563
loss:0.64443
loss:0.65241
loss:0.65754
loss:0.67071
loss:0.66568
loss:0.67096
loss:0.65653
loss:0.63934
loss:0.65787
loss:0.65868
loss:0.67304
loss:0.66575
loss:0.65554
loss:0.65855
loss:0.66117
loss:0.66023
loss:0.66465
loss:0.65565
loss:0.65565
loss:0.65534
loss:0.65038
loss:0.67276
loss:0.63785
loss:0.69407
loss:0.65655
loss:0.65397
loss:0.65530
loss:0.65396
loss:0.66629
loss:0.61658
loss:0.64422
loss:0.65530
loss:0.65093
loss:0.65138
loss:0.65397
loss:0.64431
loss:0.65607
loss:0.66483
loss:0.66824
loss:0.63643
loss:0.66334
loss:0.65067
loss:0.67477
loss:0.65089
loss:0.66645
loss:0.65170
loss:0.64991
loss:0.65671
loss:0.63525
loss:0.66740
loss:0.65917
loss:0.65607
loss:0.64750
loss:0.66352
loss:0.65599
loss:0.67381
loss:0.66788
loss:0.67039
loss:0.66365
loss:0.63018
loss:0.66047
loss:0.65263
loss:0.65999
loss:0.65519
loss:0.65050
loss:0.63911
loss:0.66676
loss:0.65215
loss:0.65701
loss:0.64674
loss:0.63694
loss:0.66463
loss:0.67194
loss:0.66087
loss:0.65372
loss:0.67057
loss:0.64850
loss:0.65196
loss:0.65830
loss:0.67407
loss:0.66481
loss:0.64764
loss:0.67543
loss:0.65758
loss:0.63964
loss:0.63738
loss:0.64458
loss:0.63796
loss:0.64376
loss:0.65966
loss:0.65195
loss:0.65806
loss:0.62922
loss:0.67659
loss:0.63782
loss:0.66520
loss:0.65631
loss:0.64798
loss:0.65381
loss:0.67107
loss:0.64786
loss:0.65706
loss:0.65190
loss:0.65827
loss:0.65811
loss:0.65115
loss:0.66454
loss:0.67029
loss:0.66545
loss:0.67605
loss:0.65635
loss:0.65615
loss:0.65249
loss:0.65333
loss:0.64656
loss:0.64776
loss:0.66854
loss:0.65656
loss:0.66438
loss:0.66439
loss:0.65035
loss:0.64033
loss:0.64184
loss:0.65894
loss:0.66415
loss:0.65968
loss:0.64980
loss:0.64148
loss:0.64257
loss:0.65133
loss:0.65212
loss:0.65322
loss:0.67377
loss:0.66929
loss:0.67070
loss:0.65993
loss:0.65533
loss:0.66274
loss:0.65980
loss:0.65712
loss:0.64883
loss:0.66942
loss:0.65983
loss:0.66505
loss:0.66948
loss:0.65957
loss:0.66079
loss:0.64512
loss:0.65226
loss:0.65160
loss:0.65865
loss:0.65817
loss:0.65403
loss:0.64624
loss:0.65644
loss:0.65494
loss:0.63946
loss:0.64054
loss:0.64769
loss:0.66020
loss:0.64777
loss:0.64849
loss:0.64779
loss:0.65660
loss:0.66092
loss:0.63569
loss:0.66273
loss:0.62671
loss:0.63050
loss:0.64863
loss:0.64694
loss:0.64357
loss:0.65161
loss:0.65649
loss:0.64989
loss:0.66887
loss:0.65654
loss:0.63991
loss:0.66011
loss:0.64368
loss:0.64401
loss:0.65523
loss:0.65195
loss:0.65697
loss:0.65673
loss:0.65230
loss:0.67421
loss:0.65930
loss:0.65980
loss:0.67248
loss:0.66098
loss:0.64481
loss:0.63308
loss:0.64697
loss:0.67564
loss:0.66501
loss:0.66060
loss:0.65404
loss:0.65504
loss:0.66546
loss:0.66108
loss:0.64019
loss:0.63760
loss:0.66268
loss:0.65253
loss:0.66966
loss:0.65191
loss:0.65946
loss:0.64416
loss:0.67128
loss:0.64392
loss:0.65634
loss:0.68388
loss:0.64450
loss:0.66246
loss:0.65347
loss:0.66191
loss:0.64905
loss:0.65414
loss:0.66311
loss:0.66115
loss:0.63493
loss:0.65428
loss:0.66133
loss:0.65756
loss:0.65608
loss:0.64133
loss:0.64818
loss:0.65263
loss:0.64176
loss:0.63988
loss:0.66769
loss:0.63649
loss:0.65396
loss:0.66275
loss:0.65312
loss:0.64005
loss:0.65273
loss:0.66756
loss:0.65712
loss:0.65620
loss:0.65808
loss:0.65708
loss:0.66150
loss:0.67015
loss:0.66441
loss:0.65523
loss:0.65408
loss:0.64401
loss:0.63593
loss:0.63791
loss:0.68248
loss:0.64841
loss:0.67505
Evaluation at Epoch 3/4. Step:9969/13292. AccuracyMetric: acc=0.547377

loss:0.65224
loss:0.63548
loss:0.63367
loss:0.65010
loss:0.64045
loss:0.63802
loss:0.62963
loss:0.63761
loss:0.65709
loss:0.62865
loss:0.63280
loss:0.63789
loss:0.64353
loss:0.63391
loss:0.65154
loss:0.64194
loss:0.64098
loss:0.63955
loss:0.65332
loss:0.62928
loss:0.62323
loss:0.63167
loss:0.61725
loss:0.64997
loss:0.60136
loss:0.63695
loss:0.64931
loss:0.63886
loss:0.64151
loss:0.65298
loss:0.63977
loss:0.64277
loss:0.64189
loss:0.64220
loss:0.63015
loss:0.63176
loss:0.63452
loss:0.67905
loss:0.63289
loss:0.64142
loss:0.63720
loss:0.61903
loss:0.64212
loss:0.62405
loss:0.63507
loss:0.63590
loss:0.64043
loss:0.63693
loss:0.63503
loss:0.64090
loss:0.64275
loss:0.62303
loss:0.63977
loss:0.65858
loss:0.65056
loss:0.61779
loss:0.63947
loss:0.64122
loss:0.63887
loss:0.64258
loss:0.64297
loss:0.61863
loss:0.62671
loss:0.62994
loss:0.63416
loss:0.64976
loss:0.64823
loss:0.63450
loss:0.64202
loss:0.64753
loss:0.63660
loss:0.63416
loss:0.64021
loss:0.62895
loss:0.62710
loss:0.64647
loss:0.65626
loss:0.64205
loss:0.63908
loss:0.63040
loss:0.63292
loss:0.64120
loss:0.63854
loss:0.66552
loss:0.62858
loss:0.64248
loss:0.64913
loss:0.64381
loss:0.62107
loss:0.65249
loss:0.64208
loss:0.63837
loss:0.64060
loss:0.63452
loss:0.63103
loss:0.65445
loss:0.63916
loss:0.64145
loss:0.62955
loss:0.64411
loss:0.66615
loss:0.62454
loss:0.65067
loss:0.62894
loss:0.61216
loss:0.63944
loss:0.62942
loss:0.62436
loss:0.62005
loss:0.64896
loss:0.62758
loss:0.63976
loss:0.65518
loss:0.61976
loss:0.64286
loss:0.64282
loss:0.62938
loss:0.64423
loss:0.63224
loss:0.65235
loss:0.65140
loss:0.62156
loss:0.64113
loss:0.63805
loss:0.64690
loss:0.62649
loss:0.63639
loss:0.64495
loss:0.65955
loss:0.63694
loss:0.64093
loss:0.61105
loss:0.64561
loss:0.64299
loss:0.64002
loss:0.63659
loss:0.63898
loss:0.64188
loss:0.65098
loss:0.63960
loss:0.64723
loss:0.64851
loss:0.62705
loss:0.63187
loss:0.64908
loss:0.62935
loss:0.63965
loss:0.63456
loss:0.63551
loss:0.60869
loss:0.61313
loss:0.64423
loss:0.64215
loss:0.61475
loss:0.62680
loss:0.64142
loss:0.61918
loss:0.64634
loss:0.60918
loss:0.63720
loss:0.64334
loss:0.62587
loss:0.62344
loss:0.63540
loss:0.63608
loss:0.62772
loss:0.63750
loss:0.62755
loss:0.61376
loss:0.65564
loss:0.62175
loss:0.62051
loss:0.63456
loss:0.62966
loss:0.64083
loss:0.64768
loss:0.65300
loss:0.63448
loss:0.63806
loss:0.63476
loss:0.66907
loss:0.63061
loss:0.64045
loss:0.63778
loss:0.64934
loss:0.64100
loss:0.65929
loss:0.61004
loss:0.63833
loss:0.65419
loss:0.64181
loss:0.66323
loss:0.62174
loss:0.62296
loss:0.64479
loss:0.62791
loss:0.64092
loss:0.64906
loss:0.64627
loss:0.64910
loss:0.64256
loss:0.64646
loss:0.65026
loss:0.63743
loss:0.64521
loss:0.63844
loss:0.65103
loss:0.65541
loss:0.64148
loss:0.65555
loss:0.65614
loss:0.66268
loss:0.64217
loss:0.63098
loss:0.63905
loss:0.64151
loss:0.63167
loss:0.63224
loss:0.64302
loss:0.62428
loss:0.63106
loss:0.61835
loss:0.62971
loss:0.63612
loss:0.66663
loss:0.61843
loss:0.63610
loss:0.62042
loss:0.66317
loss:0.65337
loss:0.65206
loss:0.64163
loss:0.64092
loss:0.62902
loss:0.60658
loss:0.66287
loss:0.63774
loss:0.63257
loss:0.65544
loss:0.63773
loss:0.61408
loss:0.66081
loss:0.64627
loss:0.64434
loss:0.64189
loss:0.64138
loss:0.63957
loss:0.64460
loss:0.63415
loss:0.63138
loss:0.64574
loss:0.62878
loss:0.63474
loss:0.64021
loss:0.62369
loss:0.64399
loss:0.65430
loss:0.65310
loss:0.64830
loss:0.64201
loss:0.64713
loss:0.63039
loss:0.64855
loss:0.64016
loss:0.67237
loss:0.63914
loss:0.64896
loss:0.64798
loss:0.65452
loss:0.62723
loss:0.61817
loss:0.64112
loss:0.63724
loss:0.64292
loss:0.62938
loss:0.65799
loss:0.62157
loss:0.64630
loss:0.63939
loss:0.64041
loss:0.64592
loss:0.66486
loss:0.62487
loss:0.65682
loss:0.63074
loss:0.64691
loss:0.63877
loss:0.63509
loss:0.63788
loss:0.64994
loss:0.62331
loss:0.64981
loss:0.63279
loss:0.65418
loss:0.61726
loss:0.63948
loss:0.62958
loss:0.64847
loss:0.65506
loss:0.64758
loss:0.64990
loss:0.66872
loss:0.64772
loss:0.64063
loss:0.66542
loss:0.62592
loss:0.63473
loss:0.65390
loss:0.62997
loss:0.65140
loss:0.63808
loss:0.63748
loss:0.60899
loss:0.65398
loss:0.64000
loss:0.63615
loss:0.66213
loss:0.63207
loss:0.63525
loss:0.64124
loss:0.65212
loss:0.63132
loss:0.64105
loss:0.62310
loss:0.63774
loss:0.62309
loss:0.65360
loss:0.64459
loss:0.62955
loss:0.64235
loss:0.63708
loss:0.61884
loss:0.63698
loss:0.64374
loss:0.65399
loss:0.63062
loss:0.64142
loss:0.62370
loss:0.60509
loss:0.62628
loss:0.63861
loss:0.63479
loss:0.62672
loss:0.64609
loss:0.64975
loss:0.62154
loss:0.62118
loss:0.64756
loss:0.64996
loss:0.63308
loss:0.64998
loss:0.65028
loss:0.62474
loss:0.63723
loss:0.64274
loss:0.63852
loss:0.65715
loss:0.65950
loss:0.63801
loss:0.62627
loss:0.61590
loss:0.63220
loss:0.66498
loss:0.62984
loss:0.62693
loss:0.64312
loss:0.64869
loss:0.61765
loss:0.61594
loss:0.63537
loss:0.64281
loss:0.62622
loss:0.63274
loss:0.64961
loss:0.62889
loss:0.64985
loss:0.64542
loss:0.64484
loss:0.64301
loss:0.63993
loss:0.64407
loss:0.63448
loss:0.64348
loss:0.64887
loss:0.63970
loss:0.64290
loss:0.64023
loss:0.63727
loss:0.63179
loss:0.64609
loss:0.62097
loss:0.65105
loss:0.62835
loss:0.66384
loss:0.64187
loss:0.63689
loss:0.64518
loss:0.63699
loss:0.64055
loss:0.62502
loss:0.64081
loss:0.62145
loss:0.65166
loss:0.63676
loss:0.64122
loss:0.63515
loss:0.63601
loss:0.61397
loss:0.65665
loss:0.62950
loss:0.62994
loss:0.62227
loss:0.64321
loss:0.63814
loss:0.63153
loss:0.63336
loss:0.63544
loss:0.63076
loss:0.64025
loss:0.64175
loss:0.63375
loss:0.64201
loss:0.62523
loss:0.64223
loss:0.64013
loss:0.64492
loss:0.64190
loss:0.63715
loss:0.63003
loss:0.62889
loss:0.62466
loss:0.63605
loss:0.64018
loss:0.62309
loss:0.61685
loss:0.63614
loss:0.62169
loss:0.64523
loss:0.63810
loss:0.63433
loss:0.63668
loss:0.61487
loss:0.64644
loss:0.65093
loss:0.64141
loss:0.63922
loss:0.62497
loss:0.64218
loss:0.63805
loss:0.63769
loss:0.63162
loss:0.64323
loss:0.65327
loss:0.62724
loss:0.65232
loss:0.64662
loss:0.62693
loss:0.65076
loss:0.62101
loss:0.64199
loss:0.63973
loss:0.62957
loss:0.61629
loss:0.64697
loss:0.64383
loss:0.65227
loss:0.61766
loss:0.64147
loss:0.64737
loss:0.62037
loss:0.59119
loss:0.62874
loss:0.65173
loss:0.62493
loss:0.63100
loss:0.65770
loss:0.63292
loss:0.64878
loss:0.63109
loss:0.62495
loss:0.65951
loss:0.64732
loss:0.64938
loss:0.62731
loss:0.63465
loss:0.62707
loss:0.63788
loss:0.64015
loss:0.65135
loss:0.63064
loss:0.63031
loss:0.63221
loss:0.64149
loss:0.62067
loss:0.64108
loss:0.63700
loss:0.65528
loss:0.63236
loss:0.63253
loss:0.62560
loss:0.61542
loss:0.63755
loss:0.65501
loss:0.62036
loss:0.66670
loss:0.65735
loss:0.64625
loss:0.64613
loss:0.60678
loss:0.62543
loss:0.63485
loss:0.60293
loss:0.64672
loss:0.62608
loss:0.62203
loss:0.63277
loss:0.64321
loss:0.61129
loss:0.66478
loss:0.63417
loss:0.62831
loss:0.65206
loss:0.61736
loss:0.63679
loss:0.63295
loss:0.62746
loss:0.61239
loss:0.62738
loss:0.63004
loss:0.64348
loss:0.61736
loss:0.63869
loss:0.64604
loss:0.64984
loss:0.63389
loss:0.61479
loss:0.63011
loss:0.64576
loss:0.62518
loss:0.63282
loss:0.64490
loss:0.62954
loss:0.63850
loss:0.63871
loss:0.61114
loss:0.62419
loss:0.60155
loss:0.63520
loss:0.63771
loss:0.62646
loss:0.62887
loss:0.63121
loss:0.63513
loss:0.64963
loss:0.65133
loss:0.63562
loss:0.62758
loss:0.61000
loss:0.63093
loss:0.64600
loss:0.64721
loss:0.61799
loss:0.65145
loss:0.62935
loss:0.60836
loss:0.66124
loss:0.62586
loss:0.65403
loss:0.63498
loss:0.62032
loss:0.64360
loss:0.62479
loss:0.62103
loss:0.63242
loss:0.63168
loss:0.64038
loss:0.64155
loss:0.64614
loss:0.64732
loss:0.62923
loss:0.62524
loss:0.62202
loss:0.64098
loss:0.61725
loss:0.66258
loss:0.65131
loss:0.63740
loss:0.63959
loss:0.66538
loss:0.60663
loss:0.63721
loss:0.62886
loss:0.61690
loss:0.64338
loss:0.61551
loss:0.63700
loss:0.66835
loss:0.64787
loss:0.64947
loss:0.64269
loss:0.63444
loss:0.63770
loss:0.63425
loss:0.64027
loss:0.64633
loss:0.63111
loss:0.63194
loss:0.64407
loss:0.64028
loss:0.64176
loss:0.65167
loss:0.62107
loss:0.61348
loss:0.63041
loss:0.63337
loss:0.62385
loss:0.63666
loss:0.63947
loss:0.63758
loss:0.66031
loss:0.62606
loss:0.61752
loss:0.61970
loss:0.64313
loss:0.62285
loss:0.60962
loss:0.63945
loss:0.65739
loss:0.61301
loss:0.60769
loss:0.63140
loss:0.64587
loss:0.63599
loss:0.64272
loss:0.61861
loss:0.63994
loss:0.62369
loss:0.66520
loss:0.65559
loss:0.60159
loss:0.60699
loss:0.63492
loss:0.64941
loss:0.61415
loss:0.62381
loss:0.62567
loss:0.62414
loss:0.65010
loss:0.64118
loss:0.62516
loss:0.64953
loss:0.62720
loss:0.64100
loss:0.66038
loss:0.64380
loss:0.61644
loss:0.62810
loss:0.62855
loss:0.63553
loss:0.59635
loss:0.63186
loss:0.62920
loss:0.63828
loss:0.64047
loss:0.63972
Evaluation at Epoch 4/4. Step:13292/13292. AccuracyMetric: acc=0.547838


In Epoch:2/Step:6646, got best dev performance:AccuracyMetric: acc=0.552749
Reloaded the best model.
Train Done.
[tester] 
AccuracyMetric: acc=0.552749
Test Done.
Predict the answer with best model...
(44772, 2)
Predict Done. 5730816 records
true sample count:43292
Add 0 default result in predict.
Predict Done, results saved to ../../data/results/CNNText_essay_at_least_1_teacher_referred_donor
